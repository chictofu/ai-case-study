# ai-case-study
a first challenge
# Anthropic

>One reason is that 'anthropic' means relating to humans, and a lot of what has been important for us, as we're working on these ever more powerful generative AI tools that are interacting with the world, is wanting to make sure that humans are still at the center of that story.

## Intro.
### Anthropic, an AI safety and research company, was founded by former members of OpenAI, including siblings Dario and Daniela Amodei. The idea for Anthropic arose primarily from a desire to focus intensively on AI safety and to explore different approaches in the development of artificial intelligence. The company aims to create AI systems that are steerable, interpretable, and robustly safe. The company raised $124 million in a Series A funding round. This funding round was announced in May 2021 and included investments from prominent tech industry figures and venture capital firms.
### One of the key motivations for founding Anthropic was to further research into the alignment of AI systems with human intentions, ensuring that these systems behave in ways that are beneficial to humanity.


## Some major market competitors are:

1. *OpenAI*
2. *DeepMind*
3. *Google AI*
4. *Microsoft Research*
5. *IBM Watson*
6. *Meta AI*


## Anthropic's main products
 ### One of Anthropic's key products is Claude, an AI model designed to perform complex cognitive tasks, analyze images, generate code, and handle multilingual processing. The latest version, Claude 3, includes three models—Opus, Sonnet, and Haiku—each optimized for different levels of performance and tasks. 

### Ref Links: 
### [Claude 3](https://www.anthropic.com/news/claude-3-family)
### [Amazon](https://aws.amazon.com/bedrock/claude/) 
